<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.6.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><meta name=author content="Nobuyuki Umetani"><meta name=description content="This paper introduces a generative model for 3D surfaces based on a representation of shapes with mean curvature and metric, which are invariant under rigid transformation. Hence, compared with existing 3D machine learning frameworks, our model substantially reduces the influence of translation and rotation. In addition, the local structure of shapes will be more precisely captured, since the curvature is explicitly encoded in our model. Specifically, every surface is first conformally mapped to a canonical domain, such as a unit disk or a unit sphere. Then, it is represented by two functions&#34;:&#34; the mean curvature half‐density and the vertex density, over this canonical domain. Assuming that input shapes follow a certain distribution in a latent space, we use the variational autoencoder to learn the latent space representation. After the learning, we can generate variations of shapes by randomly sampling the distribution in the latent space. Surfaces with triangular meshes can be reconstructed from the generated data by applying isotropic remeshing and spin transformation, which is given by Dirac equation. We demonstrate the effectiveness of our model on datasets of man‐made and biological shapes and compare the results with other methods."><link rel=alternate hreflang=en-us href=https://cgenglab.github.io/en/publication/cgf20_curvature/><meta name=theme-color content="#3f51b5"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.66ff373774f747ff53fc28e99b282768.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><link rel=manifest href=/en/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu1ba632f0a29c03dec65ff229bd3e10bd_12003_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu1ba632f0a29c03dec65ff229bd3e10bd_12003_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://cgenglab.github.io/en/publication/cgf20_curvature/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="Interactive Graphics & Engineering Lab"><meta property="og:url" content="https://cgenglab.github.io/en/publication/cgf20_curvature/"><meta property="og:title" content="A Curvature and Density‐based Generative Representation of Shapes | Interactive Graphics & Engineering Lab"><meta property="og:description" content="This paper introduces a generative model for 3D surfaces based on a representation of shapes with mean curvature and metric, which are invariant under rigid transformation. Hence, compared with existing 3D machine learning frameworks, our model substantially reduces the influence of translation and rotation. In addition, the local structure of shapes will be more precisely captured, since the curvature is explicitly encoded in our model. Specifically, every surface is first conformally mapped to a canonical domain, such as a unit disk or a unit sphere. Then, it is represented by two functions&#34;:&#34; the mean curvature half‐density and the vertex density, over this canonical domain. Assuming that input shapes follow a certain distribution in a latent space, we use the variational autoencoder to learn the latent space representation. After the learning, we can generate variations of shapes by randomly sampling the distribution in the latent space. Surfaces with triangular meshes can be reconstructed from the generated data by applying isotropic remeshing and spin transformation, which is given by Dirac equation. We demonstrate the effectiveness of our model on datasets of man‐made and biological shapes and compare the results with other methods."><meta property="og:image" content="https://cgenglab.github.io/en/publication/cgf20_curvature/featured.jpg"><meta property="twitter:image" content="https://cgenglab.github.io/en/publication/cgf20_curvature/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2020-09-05T00:00:00+00:00"><meta property="article:modified_time" content="2020-09-05T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://cgenglab.github.io/en/publication/cgf20_curvature/"},"headline":"A Curvature and Density‐based Generative Representation of Shapes","image":["https://cgenglab.github.io/en/publication/cgf20_curvature/featured.jpg"],"datePublished":"2020-09-05T00:00:00Z","dateModified":"2020-09-05T00:00:00Z","author":{"@type":"Person","name":"Zi Ye"},"publisher":{"@type":"Organization","name":"Interactive Graphics \u0026 Engineering Lab","logo":{"@type":"ImageObject","url":"https://cgenglab.github.io/media/icon_hu1ba632f0a29c03dec65ff229bd3e10bd_12003_192x192_fill_lanczos_center_3.png"}},"description":"This paper introduces a generative model for 3D surfaces based on a representation of shapes with mean curvature and metric, which are invariant under rigid transformation. Hence, compared with existing 3D machine learning frameworks, our model substantially reduces the influence of translation and rotation. In addition, the local structure of shapes will be more precisely captured, since the curvature is explicitly encoded in our model. Specifically, every surface is first conformally mapped to a canonical domain, such as a unit disk or a unit sphere. Then, it is represented by two functions\":\" the mean curvature half‐density and the vertex density, over this canonical domain. Assuming that input shapes follow a certain distribution in a latent space, we use the variational autoencoder to learn the latent space representation. After the learning, we can generate variations of shapes by randomly sampling the distribution in the latent space. Surfaces with triangular meshes can be reconstructed from the generated data by applying isotropic remeshing and spin transformation, which is given by Dirac equation. We demonstrate the effectiveness of our model on datasets of man‐made and biological shapes and compare the results with other methods."}</script><title>A Curvature and Density‐based Generative Representation of Shapes | Interactive Graphics & Engineering Lab</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=c601857006f74fcf723e490e809a40b1><script src=/js/wowchemy-init.min.613040fe4f2c0f007b4dcb64404201cb.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/en/>Interactive Graphics & Engineering Lab</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/en/>Interactive Graphics & Engineering Lab</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/en/#slider><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/en/#people><span>People</span></a></li><li class=nav-item><a class=nav-link href=/en/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/en/#teaching><span>Teaching</span></a></li><li class=nav-item><a class=nav-link href=/en/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>A Curvature and Density‐based Generative Representation of Shapes</h1><div class=article-metadata><div><span><a href=/en/author/zi-ye/>Zi Ye</a></span>, <span><a href=/en/author/nobuyuki-umetani/>Nobuyuki Umetani</a></span>, <span><a href=/en/author/takeo-igarashi/>Takeo Igarashi</a></span>, <span><a href=/en/author/tim-hoffmann/>Tim Hoffmann</a></span></div><span class=article-date>September 2020</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://doi.org/10.1111/cgf.14094 target=_blank rel=noopener>Wiley Online Library</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:252px><div style=position:relative><img src=/en/publication/cgf20_curvature/featured_hu95775a5abf46444244a1ea0ffc368705_188195_720x2500_fit_q75_h2_lanczos.webp width=720 height=252 alt class=featured-image></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>This paper introduces a generative model for 3D surfaces based on a representation of shapes with mean curvature and metric, which are invariant under rigid transformation. Hence, compared with existing 3D machine learning frameworks, our model substantially reduces the influence of translation and rotation. In addition, the local structure of shapes will be more precisely captured, since the curvature is explicitly encoded in our model. Specifically, every surface is first conformally mapped to a canonical domain, such as a unit disk or a unit sphere. Then, it is represented by two functions":" the mean curvature half‐density and the vertex density, over this canonical domain. Assuming that input shapes follow a certain distribution in a latent space, we use the variational autoencoder to learn the latent space representation. After the learning, we can generate variations of shapes by randomly sampling the distribution in the latent space. Surfaces with triangular meshes can be reconstructed from the generated data by applying isotropic remeshing and spin transformation, which is given by Dirac equation. We demonstrate the effectiveness of our model on datasets of man‐made and biological shapes and compare the results with other methods.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/en/publication/#2>Journal article</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9">Computer Graphics Forum 2020</div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/en/tag/machine-learning/>Machine Learning</a>
<a class="badge badge-light" href=/en/tag/geometry-processing/>Geometry Processing</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://cgenglab.github.io/en/publication/cgf20_curvature/&text=A%20Curvature%20and%20Density%e2%80%90based%20Generative%20Representation%20of%20Shapes" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://cgenglab.github.io/en/publication/cgf20_curvature/&t=A%20Curvature%20and%20Density%e2%80%90based%20Generative%20Representation%20of%20Shapes" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=A%20Curvature%20and%20Density%e2%80%90based%20Generative%20Representation%20of%20Shapes&body=https://cgenglab.github.io/en/publication/cgf20_curvature/" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://cgenglab.github.io/en/publication/cgf20_curvature/&title=A%20Curvature%20and%20Density%e2%80%90based%20Generative%20Representation%20of%20Shapes" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=A%20Curvature%20and%20Density%e2%80%90based%20Generative%20Representation%20of%20Shapes%20https://cgenglab.github.io/en/publication/cgf20_curvature/" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://cgenglab.github.io/en/publication/cgf20_curvature/&title=A%20Curvature%20and%20Density%e2%80%90based%20Generative%20Representation%20of%20Shapes" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=/en/author/nobuyuki-umetani/><img class="avatar mr-3 avatar-circle" src=/en/author/nobuyuki-umetani/avatar_hucc2c9d478ae12dfb186edeea2135d6eb_1558945_270x270_fill_q75_lanczos_center.jpg alt="Nobuyuki Umetani"></a><div class=media-body><h5 class=card-title><a href=/en/author/nobuyuki-umetani/>Nobuyuki Umetani</a></h5><h6 class=card-subtitle>Associate Professor</h6><p class=card-text>My research interests include interactive smart engineering design tool using physics simulation and machine learning.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:n.umetani@gmail.com><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=pZyOTEQAAAAJ&hl=en" target=_blank rel=noopener><i class="fas fa-graduation-cap"></i></a></li><li><a href=https://github.com/nobuyuki83 target=_blank rel=noopener><i class="fab fa-github"></i></a></li></ul></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2023 Nobuyuki Umetani</p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js type=module></script>
<script src=/en/js/wowchemy.min.0c87e422cc854f7581df96b2cf468177.js></script>
<script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>