[{"authors":null,"categories":null,"content":"Nobuyuki Umetani is an associate professor at the University of Tokyo. Previously, he was a research scientist at Autodesk Research, leading the Design and Fabrication group. He was a postdoctoral researcher at Autodesk Research and Disney Research Zurich. He received his Ph.D. degree in 2012 from The University of Tokyo under the supervision of Takeo Igarashi. He also spent one year at Columbia University and in TU Delft, and spent three months in Microsoft Research Asia and in UCL. He won the Microsoft Research Asia fellowship in 2011 and AsiaGraphics Young Researcher Award in 2018.\nThe principal research question he addresses through his studies is: how to integrate real-time physical simulation into an interactive geometric modeling procedure to facilitate creativity. He is broadly interested in physics simulation, especially the finite element method, applied for computer animation, biomechanics, and mechanical engineering.\nDownload my resumé.\n","date":1667174400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667174400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://cgenglab.github.io/en/author/nobuyuki-umetani/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/nobuyuki-umetani/","section":"authors","summary":"Nobuyuki Umetani is an associate professor at the University of Tokyo. Previously, he was a research scientist at Autodesk Research, leading the Design and Fabrication group. He was a postdoctoral researcher at Autodesk Research and Disney Research Zurich.","tags":null,"title":"Nobuyuki Umetani","type":"authors"},{"authors":["moroto"],"categories":null,"content":"Interests Computer Graphics Competitive Programming Camera (not photographer, but videographer) Video Production (Adobe After Effects, etc.) Awards and Honors ACM SIGGRAPH : SIGGRAPH Asia 2022 Best Technical Paper Award JST Support for Pioneering Research Initiated by the Next Generation (SPRING GX) 2021-2024 ACM ICPC 2018 World Finals About Avater The avatar image consists of 425 translucent circles. Click here to see the full quality image. This was generated using the solver for the TopCoder Marathon Match 95.\nLinks Mitou-Meikan (Japanese) ","date":1667174400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667174400,"objectID":"d35ec264361d7330108864e18c9d8d86","permalink":"https://cgenglab.github.io/en/author/yuji-moroto/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/yuji-moroto/","section":"authors","summary":"Interests Computer Graphics Competitive Programming Camera (not photographer, but videographer) Video Production (Adobe After Effects, etc.) Awards and Honors ACM SIGGRAPH : SIGGRAPH Asia 2022 Best Technical Paper Award JST Support for Pioneering Research Initiated by the Next Generation (SPRING GX) 2021-2024 ACM ICPC 2018 World Finals About Avater The avatar image consists of 425 translucent circles.","tags":null,"title":"Yuji Moroto","type":"authors"},{"authors":["kenji-tojo"],"categories":null,"content":"Links Personal Website\n","date":1655942400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1655942400,"objectID":"544ab0c19aac446052390625759458af","permalink":"https://cgenglab.github.io/en/author/kenji-tojo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/kenji-tojo/","section":"authors","summary":"Links Personal Website","tags":null,"title":"Kenji Tojo","type":"authors"},{"authors":null,"categories":null,"content":"My Personal Page\n","date":1652227200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1652227200,"objectID":"94abf28ff1b0710a5e9b70b7c39e0fe5","permalink":"https://cgenglab.github.io/en/author/kinuwaki-shinichi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/kinuwaki-shinichi/","section":"authors","summary":"My Personal Page","tags":null,"title":"Kinuwaki Shinichi","type":"authors"},{"authors":["yuanwei"],"categories":null,"content":"I’m a master student of the Department of Creative Informatics at the University of Tokyo, supervised by Prof. Nobuyuki Umetani. I obtained my bachelor degree in Computer Science and Technology from Peking University. My research interest is Computer Graphics, especially realistic and real-time simulation. Besides, I’m also excited in superhero movies, astrophotography, as well as discoveries of relationship between different languages. If you have similar interests, I’m very glad to have a coffee time with you :)\n","date":1652227200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1652227200,"objectID":"6a7f25860c2e8fe28d138313946371bc","permalink":"https://cgenglab.github.io/en/author/yuanwei-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/yuanwei-zhang/","section":"authors","summary":"I’m a master student of the Department of Creative Informatics at the University of Tokyo, supervised by Prof. Nobuyuki Umetani. I obtained my bachelor degree in Computer Science and Technology","tags":null,"title":"Yuanwei Zhang","type":"authors"},{"authors":["yifei"],"categories":null,"content":"Biography I have a great interest in research about Data-Driven Animation and Machine Learning. I received my bachelor’s degree from New York Institute of Technology. Hobbies including developing indie game, watching anime and discovering traditional tasty food (=^･ω･^)y＝\nResearch Interests Machine Learning Character Animation Hobbies Indie Game Development Anime Traveling ","date":1646092800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1646092800,"objectID":"238beeafe03332ba705a471d84487889","permalink":"https://cgenglab.github.io/en/author/yifei-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/yifei-chen/","section":"authors","summary":"Biography I have a great interest in research about Data-Driven Animation and Machine Learning. I received my bachelor’s degree from New","tags":null,"title":"Yifei Chen","type":"authors"},{"authors":["meistdan"],"categories":null,"content":"My Personal Page\n","date":1636934400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1636934400,"objectID":"34f44093fd18f07fc729657a33d8b8e8","permalink":"https://cgenglab.github.io/en/author/daniel-meister/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/daniel-meister/","section":"authors","summary":"My Personal Page","tags":null,"title":"Daniel Meister","type":"authors"},{"authors":["smukherjee2016"],"categories":null,"content":"My Personal Page\n","date":1636934400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1636934400,"objectID":"569d6277668d3691a051d612d765ab48","permalink":"https://cgenglab.github.io/en/author/sabyasachi-mukherjee/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/sabyasachi-mukherjee/","section":"authors","summary":"My Personal Page","tags":null,"title":"Sabyasachi Mukherjee","type":"authors"},{"authors":["rexwest"],"categories":null,"content":"Rex West is a Ph.D student of the Department of Creative Informatics at The University of Tokyo.\nOnline CV cv.rexwe.st\n","date":1635638400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1635638400,"objectID":"837f36f562022bd88f34c5596800c95c","permalink":"https://cgenglab.github.io/en/author/rex-west/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/rex-west/","section":"authors","summary":"Rex West is a Ph.D student of the Department of Creative Informatics at The University of Tokyo.\nOnline CV cv.rexwe.st","tags":null,"title":"Rex West","type":"authors"},{"authors":["bojian_li"],"categories":null,"content":"Links Personal Website\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6b5159fbe52d5d08bf9355d831728b5e","permalink":"https://cgenglab.github.io/en/author/bojian-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/bojian-li/","section":"authors","summary":"Links Personal Website","tags":null,"title":"Bojian Li","type":"authors"},{"authors":["jiajun_han"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6f3776b477d95685e873a6998831bab5","permalink":"https://cgenglab.github.io/en/author/jiajun-han/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/jiajun-han/","section":"authors","summary":"","tags":null,"title":"Jiajun Han","type":"authors"},{"authors":["liam"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ee7bd710c25f684f7aa0b636f93daa86","permalink":"https://cgenglab.github.io/en/author/liam-s.-crouch/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/liam-s.-crouch/","section":"authors","summary":"","tags":null,"title":"Liam S. Crouch","type":"authors"},{"authors":["nnkgw"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e656816f9e184f054aa5f69711413c37","permalink":"https://cgenglab.github.io/en/author/nobuo-nakagawa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/nobuo-nakagawa/","section":"authors","summary":"","tags":null,"title":"Nobuo Nakagawa","type":"authors"},{"authors":["rintaro"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"fe5773b4019ccd564af0b4b473c3f1c6","permalink":"https://cgenglab.github.io/en/author/rintaro-sakurai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/rintaro-sakurai/","section":"authors","summary":"","tags":null,"title":"Rintaro Sakurai","type":"authors"},{"authors":["shiyun_wang"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c81694da1bc75b438d78c4e904e74627","permalink":"https://cgenglab.github.io/en/author/shiyun-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/shiyun-wang/","section":"authors","summary":"","tags":null,"title":"Shiyun Wang","type":"authors"},{"authors":["yiyi_cai"],"categories":null,"content":"Biography To create a virtual world that can do things beyond reality is really cool. My dream is that oneday I can create an anime world with fully real-time rendering and interactive simulation, obeying the “Physical laws” that I set.\nResearch Interests Anime-style rendering, Physically-based simulation Hobbies Anime, Classical music ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"498acc592562a94910c4c34dc2376d8e","permalink":"https://cgenglab.github.io/en/author/yiyi-cai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/yiyi-cai/","section":"authors","summary":"Biography To create a virtual world that can do things beyond reality is really cool. My dream is that oneday I can create an anime world with fully real-time rendering and interactive simulation, obeying the “Physical laws” that I set.","tags":null,"title":"Yiyi Cai","type":"authors"},{"authors":["ikkaku"],"categories":null,"content":"Yoshinari Ikkaku is a visiting researcher from Shima Seiki.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1402c8ef365be853161a9b84996fe553","permalink":"https://cgenglab.github.io/en/author/yoshinari-ikkaku/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/yoshinari-ikkaku/","section":"authors","summary":"Yoshinari Ikkaku is a visiting researcher from Shima Seiki.","tags":null,"title":"Yoshinari Ikkaku","type":"authors"},{"authors":["yuhan_wu"],"categories":null,"content":"Biography I love physics, coding, and game design. Currently I’m devoting most of my time into exploring how to recreate physical reality in digital world. In my spare time I make some mini games.\nResearch Interests Physics-based simulation Hobbies Indie Game ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"17df38c835bdddc701d1466371e23a6c","permalink":"https://cgenglab.github.io/en/author/yuhan-wu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/yuhan-wu/","section":"authors","summary":"Biography I love physics, coding, and game design. Currently I’m devoting most of my time into exploring how to recreate physical reality in digital world. In my spare time I make some mini games.","tags":null,"title":"Yuhan Wu","type":"authors"},{"authors":["zeyuan_he"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b32de4382098353983d31f55af2cc194","permalink":"https://cgenglab.github.io/en/author/zeyuan-he/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/zeyuan-he/","section":"authors","summary":"","tags":null,"title":"Zeyuan He","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://cgenglab.github.io/en/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/en/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":["Yuji Moroto","Nobuyuki Umetani"],"categories":null,"content":"Award This paper got the SIGGRAPH Asia 2022 Best Paper Award.\nSupplementary Materials Code We are currently preparing an implementation of a median filter using wavelet matrix for release on GitHub. Until the GitHub repository is ready for publication, we are publishing the supplementary materials code for the paper submission. This code is based on the Supplemental Material Code for “Fast median filters using separable sorting networks” [Adams 2021], with the addition of our methods. This supplementary materials includes code for CPUs, where readability is more important than speed, and code for CUDAs, where speed is the highest priority.\nDownload here (Google Drive) The GitHub version, to be released in November, will include the following updates\nImproved readability Support for multiple channels Reduced memory usage by about 40~50%. ","date":1667174400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667174400,"objectID":"797ff7cbf367447cd7fecec2bbcf64b0","permalink":"https://cgenglab.github.io/en/publication/sigga22_wmatrix_median/","publishdate":"2017-08-01T00:00:00Z","relpermalink":"/en/publication/sigga22_wmatrix_median/","section":"publication","summary":"In this paper, we have implemented a completely new constant-time median filter based on Wavelet Matrix, which can be efficiently executed by a GPU and supports HDR images.","tags":["Image Processing"],"title":"Constant Time Median Filter using 2D Wavelet Matrix","type":"publication"},{"authors":["Yuta Noma","Nobuyuki Umetani","Yoshihiro Kawahara"],"categories":null,"content":"","date":1667088e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667088e3,"objectID":"6423491ad580a476a3e8ba372e789d81","permalink":"https://cgenglab.github.io/en/publication/sigga22_fast_singularity/","publishdate":"2017-08-01T00:00:00Z","relpermalink":"/en/publication/sigga22_fast_singularity/","section":"publication","summary":"In this paper, we propose an algorithm to allow users to interactively edit the singularity positions of field-aligned stripe patterns.","tags":["Computational Fabrication","Geometry Processing","Interactive Modeling"],"title":"Fast Editing of Singularities in Field-Aligned Stripe Patterns","type":"publication"},{"authors":["Kenji Tojo","Nobuyuki Umetani"],"categories":null,"content":"","date":1655942400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655942400,"objectID":"14d168886f8f20fe3b93db6c223a1320","permalink":"https://cgenglab.github.io/en/publication/egsr22_npr/","publishdate":"2022-06-23T00:00:00Z","relpermalink":"/en/publication/egsr22_npr/","section":"publication","summary":"We investigate artistic posterization of volumetric radiance fields.","tags":["Image Processing","Rendering","Non-Photorealistic"],"title":"Recolorable Posterization of Volumetric Radiance Fields - Supplemental Video","type":"publication"},{"authors":["Yuanwei Zhang","Kinuwaki Shinichi","Nobuyuki Umetani"],"categories":null,"content":"","date":1652227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652227200,"objectID":"b84385266d5ce6d5fcf61210ab77ddcd","permalink":"https://cgenglab.github.io/en/publication/gi22_energyhair/","publishdate":"2022-05-11T00:00:00Z","relpermalink":"/en/publication/gi22_energyhair/","section":"publication","summary":"This study introduces a new sketch-based hairstyle authoring interface for virtual characters captured using multi-view stereo. The use of physics-related shape optimization in the interface allows natural-looking 3D hair shapes to be modeled from minimal user specifications.","tags":["Interactive Modeling","Physics Simulation","Hair Modeling","Digital Human"],"title":"EnergyHair: Sketch-Based Interactive Guide Hair Design Using Physics-Inspired Energy","type":"publication"},{"authors":["Kenji Tojo","Yifei Chen","Nobuyuki Umetani"],"categories":null,"content":"","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"6a6df3c0af174200b13e2b06716b5e33","permalink":"https://cgenglab.github.io/en/publication/eg22short_neuralcompression/","publishdate":"2022-03-01T00:00:00Z","relpermalink":"/en/publication/eg22short_neuralcompression/","section":"publication","summary":"We present a neural-network-based compression method to alleviate the storage cost of motion capture data. We leverage this periodicity by applying Fourier features to a multilayered perceptron network.","tags":["Data-driven Animation","Machine Learning","Character Animation"],"title":"Neural Motion Compression with Frequency-adaptive Fourier Feature Network","type":"publication"},{"authors":["Sabyasachi Mukherjee","Sayan Mukherjee","Son Hua","Nobuyuki Umetani","Daniel Meister"],"categories":null,"content":"","date":1636934400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636934400,"objectID":"a955e4ea389524e6aa231c45861a02ee","permalink":"https://cgenglab.github.io/en/publication/pg21_sequence/","publishdate":"2021-09-20T00:00:00Z","relpermalink":"/en/publication/pg21_sequence/","section":"publication","summary":"A data-driven approach to applying sequence transformation to Monte Carlo integration.","tags":["Rendering"],"title":"Neural Sequence Transformation","type":"publication"},{"authors":["Rex West"],"categories":null,"content":"","date":1635638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635638400,"objectID":"da3f12b441abdfda90624e6a222a2d6d","permalink":"https://cgenglab.github.io/en/publication/sigga21_featureline/","publishdate":"2017-08-01T00:00:00Z","relpermalink":"/en/publication/sigga21_featureline/","section":"publication","summary":"In this paper we present a path-based method for incorporating feature lines into physically-based rendering by modeling them as view-dependent, implicit light sources.","tags":["Rendering","Non-Photorealistic"],"title":"Physically-based Feature Line Rendering","type":"publication"},{"authors":["Toby Chong","I-Chao Shen","Nobuyuki Umetani","Takeo Igarashi"],"categories":null,"content":"","date":1634083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634083200,"objectID":"0aba22282af836967a16347a39e385b5","permalink":"https://cgenglab.github.io/en/publication/uist21_mannequin/","publishdate":"2017-08-01T00:00:00Z","relpermalink":"/en/publication/uist21_mannequin/","section":"publication","summary":"Virtual try-on is a promising application of computer graphics and human computer interaction that can have a profound real-world impact especially during this pandemic. Existing image-based works try to synthesize a try-on image from a single image of a target garment, but it inherently limits the ability to react to possible interactions. It is difficult to reproduce the change of wrinkles caused by pose and body size change, as well as pulling and stretching of the garment by hand.\\\n\\\nIn this paper, we propose an alternative per garment capture and synthesis workflow to handle such rich interactions by training the model with many systematically captured images. Our workflow is composed of two parts: garment capturing and clothed person image synthesis. We designed an actuated mannequin and an efficient capturing process that collects the detailed deformations of the target garments under diverse body sizes and poses.\\\n\\\nFurthermore, we proposed to use a custom-designed measurement garment, and we captured paired images of the measurement garment and the target garments. We then learn a mapping between the measurement garment and the target garments using deep image-to-image translation. The customer can then try on the target garments interactively during online shopping.\n","tags":["Cloth Modeling","Machine Learning","Interactive Modeling"],"title":"Per Garment Capture and Synthesis for Real-time Virtual Try-on","type":"publication"},{"authors":["Yuji Moroto","Toshiya Hachisuka","Nobuyuki Umetani"],"categories":null,"content":"Filtered Images Google Drive (Download All) Presentation Video YouTube Products using This Technology Fast Camera Lens Blur – A high-speed camera lens blur plug-in that works with Adobe After Effects/Premiere Pro. ","date":1624665600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624665600,"objectID":"c7b88cf6cc980fcb7f56e4660cab72e9","permalink":"https://cgenglab.github.io/en/publication/egsr21_blur/","publishdate":"2021-06-26T00:00:00Z","relpermalink":"/en/publication/egsr21_blur/","section":"publication","summary":"We present a technique for fast and accurate DoF filtering for polygonal kernels by extending the conventional axis-aligned differences to non-axis-aligned differences.","tags":["Image Processing"],"title":"Fast Polygonal Splatting using Directional Kernel Difference","type":"publication"},{"authors":["Chihiro Goto","Nobuyuki Umetani"],"categories":null,"content":"","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"fb866fd97fe9580715e3095b8a0b9266","permalink":"https://cgenglab.github.io/en/publication/eg21short_clothpattern/","publishdate":"2021-03-16T00:00:00Z","relpermalink":"/en/publication/eg21short_clothpattern/","section":"publication","summary":"We present a technique to estimate clothing patterns from a 3D geometry of a person in cloth. Our technique uses image-based deep learning to estimate the type of pattern on the projected image.","tags":["Cloth Modeling","Machine Learning"],"title":"Data-driven Garment Pattern Estimation from 3D Geometries","type":"publication"},{"authors":null,"categories":null,"content":"Congratulations to Jian Yang and Monica Hall for winning the Best Paper Award at the 2020 Conference on Wowchemy for their paper “Learning Wowchemy”.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Integer tempus augue non tempor egestas. Proin nisl nunc, dignissim in accumsan dapibus, auctor ullamcorper neque. Quisque at elit felis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget elementum odio. Cras interdum eget risus sit amet aliquet. In volutpat, nisl ut fringilla dignissim, arcu nisl suscipit ante, at accumsan sapien nisl eu eros.\nSed eu dui nec ligula bibendum dapibus. Nullam imperdiet auctor tortor, vel cursus mauris malesuada non. Quisque ultrices euismod dapibus. Aenean sed gravida risus. Sed nisi tortor, vulputate nec quam non, placerat porta nisl. Nunc varius lobortis urna, condimentum facilisis ipsum molestie eu. Ut molestie eleifend ligula sed dignissim. Duis ut tellus turpis. Praesent tincidunt, nunc sed congue malesuada, mauris enim maximus massa, eget interdum turpis urna et ante. Morbi sem nisl, cursus quis mollis et, interdum luctus augue. Aliquam laoreet, leo et accumsan tincidunt, libero neque aliquet lectus, a ultricies lorem mi a orci.\nMauris dapibus sem vel magna convallis laoreet. Donec in venenatis urna, vitae sodales odio. Praesent tortor diam, varius non luctus nec, bibendum vel est. Quisque id sem enim. Maecenas at est leo. Vestibulum tristique pellentesque ex, blandit placerat nunc eleifend sit amet. Fusce eget lectus bibendum, accumsan mi quis, luctus sem. Etiam vitae nulla scelerisque, eleifend odio in, euismod quam. Etiam porta ullamcorper massa, vitae gravida turpis euismod quis. Mauris sodales sem ac ultrices viverra. In placerat ultrices sapien. Suspendisse eu arcu hendrerit, luctus tortor cursus, maximus dolor. Proin et velit et quam gravida dapibus. Donec blandit justo ut consequat tristique.\n","date":1606867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606867200,"objectID":"2a0ec8a990dbd78a00c4e15a09364b00","permalink":"https://cgenglab.github.io/en/post/20-12-02-icml-best-paper/","publishdate":"2020-12-02T00:00:00Z","relpermalink":"/en/post/20-12-02-icml-best-paper/","section":"post","summary":"Congratulations to Jian Yang and Monica Hall for winning the Best Paper Award at the 2020 Conference on Wowchemy for their paper “Learning Wowchemy”.\n","tags":null,"title":"Jian Yang and Monica Hall Win the Best Paper Award at Wowchemy 2020","type":"post"},{"authors":null,"categories":null,"content":"Congratulations to Richard Hendricks for winning first place in the Wowchemy Prize.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Integer tempus augue non tempor egestas. Proin nisl nunc, dignissim in accumsan dapibus, auctor ullamcorper neque. Quisque at elit felis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget elementum odio. Cras interdum eget risus sit amet aliquet. In volutpat, nisl ut fringilla dignissim, arcu nisl suscipit ante, at accumsan sapien nisl eu eros.\nSed eu dui nec ligula bibendum dapibus. Nullam imperdiet auctor tortor, vel cursus mauris malesuada non. Quisque ultrices euismod dapibus. Aenean sed gravida risus. Sed nisi tortor, vulputate nec quam non, placerat porta nisl. Nunc varius lobortis urna, condimentum facilisis ipsum molestie eu. Ut molestie eleifend ligula sed dignissim. Duis ut tellus turpis. Praesent tincidunt, nunc sed congue malesuada, mauris enim maximus massa, eget interdum turpis urna et ante. Morbi sem nisl, cursus quis mollis et, interdum luctus augue. Aliquam laoreet, leo et accumsan tincidunt, libero neque aliquet lectus, a ultricies lorem mi a orci.\nMauris dapibus sem vel magna convallis laoreet. Donec in venenatis urna, vitae sodales odio. Praesent tortor diam, varius non luctus nec, bibendum vel est. Quisque id sem enim. Maecenas at est leo. Vestibulum tristique pellentesque ex, blandit placerat nunc eleifend sit amet. Fusce eget lectus bibendum, accumsan mi quis, luctus sem. Etiam vitae nulla scelerisque, eleifend odio in, euismod quam. Etiam porta ullamcorper massa, vitae gravida turpis euismod quis. Mauris sodales sem ac ultrices viverra. In placerat ultrices sapien. Suspendisse eu arcu hendrerit, luctus tortor cursus, maximus dolor. Proin et velit et quam gravida dapibus. Donec blandit justo ut consequat tristique.\n","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"be2bd15f022f0d83fe9ffd743881e70c","permalink":"https://cgenglab.github.io/en/post/20-12-01-wowchemy-prize/","publishdate":"2020-12-01T00:00:00Z","relpermalink":"/en/post/20-12-01-wowchemy-prize/","section":"post","summary":"Congratulations to Richard Hendricks for winning first place in the Wowchemy Prize.\n","tags":null,"title":"Richard Hendricks Wins First Place in the Wowchemy Prize","type":"post"},{"authors":["Jiahao Wen","Jiong Chen","Nobuyuki Umetani","Hujun Bao","Jin Huang"],"categories":null,"content":"","date":1606176e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606176e3,"objectID":"faf66d56551e2e3ccffd9eae9e4c75f0","permalink":"https://cgenglab.github.io/en/publication/cgf20_cosserat/","publishdate":"2020-11-24T00:00:00Z","relpermalink":"/en/publication/cgf20_cosserat/","section":"publication","summary":"Rod‐like one‐dimensional elastic objects often exhibit complex behaviors which pose great challenges to the discretization method for pursuing a faithful simulation. By only moving a small portion of material points, the Eulerian‐on‐Lagrangian (EoL) method already shows great adaptivity to handle sharp contact, but it is still far from enough to reproduce rich and complex geometry details arising in simulations. In this paper, we extend the discrete configuration space by unifying all Lagrangian and EoL nodes in representation for even more adaptivity with every sample being assigned with a dynamic material coordinate. However, this great extension will immediately bring in much more redundancy in the dynamic system. Therefore, we propose additional energy to control the spatial distribution of all material points, seeking to equally space them with respect to a curvature‐based density field as a monitor. This flexible approach can effectively constrain the motion of material points to resolve numerical degeneracy, while simultaneously enables them to notably slide inside the parametric domain to account for the shape parameterization. Besides, to accurately respond to sharp contact, our method can also insert or remove nodes online and adjust the energy stiffness to suppress possible jittering artifacts that could be excited in a stiff system. As a result of this hybrid rh‐adaption, our proposed method is capable of reproducing many realistic rod dynamics, such as excessive bending, twisting and knotting while only using a limited number of elements.","tags":["Physics Simulation"],"title":"A Curvature and Density‐based Generative Representation of Shapes","type":"publication"},{"authors":["Maria Larsson","Hironori Yoshida","Nobuyuki Umetani","Takeo Igarashi"],"categories":null,"content":"","date":1603152e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603152e3,"objectID":"dcc1ea427ab1299fa90b54e426e8eb07","permalink":"https://cgenglab.github.io/en/publication/uist20_tsugite/","publishdate":"2017-11-01T00:00:00Z","relpermalink":"/en/publication/uist20_tsugite/","section":"publication","summary":"We present Tsugite—an interactive system for designing and fabricating wood joints for frame structures. To design and manually craft such joints is difficult and time consuming. Our system facilitates the creation of custom joints by a modeling interface combined with computer numerical control (CNC) fabrication. The design space is a 3D grid of voxels that enables efficient geometrical analysis and combinatorial search. The interface has two modes\":\" manual editing and gallery. In the manual editing mode, the user edits a joint while receiving real-time graphical feedback and suggestions provided based on performance metrics including slidability, fabricability, and durability with regard to the direction of fiber. In the gallery mode, the user views and selects feasible joints that have been pre-calculated. When a joint design is finalized, it can be manufactured with a 3-axis CNC milling machine using a specialized path planning algorithm that ensures joint assemblability by corner rounding. This system was evaluated via a user study and by designing and fabricating joint samples and functional furniture.","tags":["Computational Fabrication","Interactive Modeling"],"title":"Tsugite: Interactive Design and Fabrication of Wood Joints","type":"publication"},{"authors":["Zi Ye","Nobuyuki Umetani","Takeo Igarashi","Tim Hoffmann"],"categories":null,"content":"","date":1599264e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599264e3,"objectID":"c601857006f74fcf723e490e809a40b1","permalink":"https://cgenglab.github.io/en/publication/cgf20_curvature/","publishdate":"2020-09-05T00:00:00Z","relpermalink":"/en/publication/cgf20_curvature/","section":"publication","summary":"This paper introduces a generative model for 3D surfaces based on a representation of shapes with mean curvature and metric, which are invariant under rigid transformation. Hence, compared with existing 3D machine learning frameworks, our model substantially reduces the influence of translation and rotation. In addition, the local structure of shapes will be more precisely captured, since the curvature is explicitly encoded in our model. Specifically, every surface is first conformally mapped to a canonical domain, such as a unit disk or a unit sphere. Then, it is represented by two functions\":\" the mean curvature half‐density and the vertex density, over this canonical domain. Assuming that input shapes follow a certain distribution in a latent space, we use the variational autoencoder to learn the latent space representation. After the learning, we can generate variations of shapes by randomly sampling the distribution in the latent space. Surfaces with triangular meshes can be reconstructed from the generated data by applying isotropic remeshing and spin transformation, which is given by Dirac equation. We demonstrate the effectiveness of our model on datasets of man‐made and biological shapes and compare the results with other methods.","tags":["Machine Learning","Geometry Processing"],"title":"A Curvature and Density‐based Generative Representation of Shapes","type":"publication"},{"authors":["Nobuyuki Umetani","Bernd Bickel"],"categories":null,"content":"","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530403200,"objectID":"66010409be6668c2473e91cc9ef26abc","permalink":"https://cgenglab.github.io/en/publication/sigg18_mlcfd/","publishdate":"2018-07-01T00:00:00Z","relpermalink":"/en/publication/sigg18_mlcfd/","section":"publication","summary":"We present a data-driven technique to instantly predict how fluid flows around various three-dimensional objects. Such simulation is useful for computational fabrication and engineering, but is usually computationally expensive since it requires solving the Navier-Stokes equation for many time steps. To accelerate the process, we propose a machine learning framework which predicts aerodynamic forces and velocity and pressure fields given a three-dimensional shape input. Handling detailed free-form three-dimensional shapes in a data-driven framework is challenging because machine learning approaches usually require a consistent parametrization of input and output. We present a novel PolyCube maps-based parametrization that can be computed for three-dimensional shapes at interactive rates. This allows us to efficiently learn the nonlinear response of the flow using a Gaussian process regression. We demonstrate the effectiveness of our approach for the interactive design and optimization of a car body.","tags":["Machine Learning","Geometry Processing","Physics Simulation","Fluid Dynamics","Interactive Modeling"],"title":"Learning Three-dimensional Flow for Interactive Aerodynamic Design","type":"publication"},{"authors":["Nobuyuki Umetani"],"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"5e0dcec371adb8c9849ea23b9c267041","permalink":"https://cgenglab.github.io/en/publication/sigga17tb_mlcarshape/","publishdate":"2017-11-01T00:00:00Z","relpermalink":"/en/publication/sigga17tb_mlcarshape/","section":"publication","summary":"We propose a new algorithm for converting unstructured triangle meshes into ones with a consistent topology for machine learning applications. We combine the orthogonal depth map computation and the shrink wrapping approach to efficiently and robustly parameterize the triangle geometry regardless of imperfections such as inverted faces, holes, and self-intersections. The converted mesh is consistently and compactly parameterized and thus is suitable for machine learning. We use an autoencoder network to extract the manifold of shapes in the same category to explore and synthesize a variety of shapes. Furthermore, we introduce a direct manipulation interface to navigate the synthesis. We demonstrate our approach with over one thousand car shapes represented in unstructured triangle meshes.","tags":["Machine Learning","Geometry Processing","Interactive Modeling"],"title":"Exploring Generative 3D Shapes Using Autoencoder Networks","type":"publication"},{"authors":["Nobuyuki Umetani","Ryan Schmidt"],"categories":null,"content":"","date":1493164800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493164800,"objectID":"1191436345ace4b18ad088f505880a9f","permalink":"https://cgenglab.github.io/en/publication/cga17_surfcuit/","publishdate":"2017-04-26T00:00:00Z","relpermalink":"/en/publication/cga17_surfcuit/","section":"publication","summary":"The SurfCuit system integrates circuits into 3D prints by mounting them on the printed surface. SurfCuit does not require tedious circuit casing design or expensive setups, allowing users to build complex, highly conductive circuit patterns for consumer-level desktop fused decomposition modeling (FDM) 3D printers and thus expediting the process of circuit construction for 3D models.","tags":["Geometry Processing","Computational Fabrication","Interactive Modeling"],"title":"SurfCuit: Surface-Mounted Circuits on 3D Prints","type":"publication"},{"authors":["Nobuyuki Umetani","Athina Panotopoulou","Ryan Schmidt","Emily Whiting"],"categories":null,"content":"","date":1477958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477958400,"objectID":"376d68f75395a0e6ff9c5344aa2fd39a","permalink":"https://cgenglab.github.io/en/publication/sigga16_printone/","publishdate":"2016-11-01T00:00:00Z","relpermalink":"/en/publication/sigga16_printone/","section":"publication","summary":"We propose a new algorithm for converting unstructured triangle meshes into ones with a consistent topology for machine learning applications. We combine the orthogonal depth map computation and the shrink wrapping approach to efficiently and robustly parameterize the triangle geometry regardless of imperfections such as inverted faces, holes, and self-intersections. The converted mesh is consistently and compactly parameterized and thus is suitable for machine learning. We use an autoencoder network to extract the manifold of shapes in the same category to explore and synthesize a variety of shapes. Furthermore, we introduce a direct manipulation interface to navigate the synthesis. We demonstrate our approach with over one thousand car shapes represented in unstructured triangle meshes.","tags":["Computational Fabrication","Physics Simulation","Geometry Processing","Sound Simulation","Interactive Modeling"],"title":"Printone: Interactive Resonance Simulation for Free-form Print-wind Instrument Design","type":"publication"},{"authors":["Andrew O. Sageman-Furnas","Nobuyuki Umetani","Ryan Schmidt"],"categories":null,"content":"","date":1446336e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446336e3,"objectID":"e616f65abf26f0a544ddba131722d78d","permalink":"https://cgenglab.github.io/en/publication/sigga15tb_meltables/","publishdate":"2015-11-01T00:00:00Z","relpermalink":"/en/publication/sigga15tb_meltables/","section":"publication","summary":"We propose a new algorithm for converting unstructured triangle meshes into ones with a consistent topology for machine learning applications. We combine the orthogonal depth map computation and the shrink wrapping approach to efficiently and robustly parameterize the triangle geometry regardless of imperfections such as inverted faces, holes, and self-intersections. The converted mesh is consistently and compactly parameterized and thus is suitable for machine learning. We use an autoencoder network to extract the manifold of shapes in the same category to explore and synthesize a variety of shapes. Furthermore, we introduce a direct manipulation interface to navigate the synthesis. We demonstrate our approach with over one thousand car shapes represented in unstructured triangle meshes.","tags":["Geometry Processing","Computational Fabrication"],"title":"Meltables: Fabrication of Complex 3D Curves by Melting","type":"publication"},{"authors":["Tobias Martin","Nobuyuki Umetani","Bernd Bickel"],"categories":null,"content":"","date":1435708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435708800,"objectID":"8163ae1b31debee6b98ebc8d9d24435e","permalink":"https://cgenglab.github.io/en/publication/sigg14_omniad/","publishdate":"2015-11-01T00:00:00Z","relpermalink":"/en/publication/sigg14_omniad/","section":"publication","summary":"This paper introduces \"OmniAD,\" a novel data-driven pipeline to model and acquire the aerodynamics of three-dimensional rigid objects. Traditionally, aerodynamics are examined through elaborate wind tunnel experiments or expensive fluid dynamics computations, and are only measured for a small number of discrete wind directions. OmniAD allows the evaluation of aerodynamic forces, such as drag and lift, for any incoming wind direction using a novel representation based on spherical harmonics. Our data-driven technique acquires the aerodynamic properties of an object simply by capturing its falling motion using a single camera. Once model parameters are estimated, OmniAD enables realistic real-time simulation of rigid bodies, such as the tumbling and gliding of leaves, without simulating the surrounding air. In addition, we propose an intuitive user interface based on OmniAD to interactively design three-dimensional kites that actually fly. Various non-traditional kites were designed to demonstrate the physical validity of our model.","tags":["Machine Learning","Physics Simulation","Fluid Dynamics","Computational Fabrication","Interactive Modeling","Data-driven Animation"],"title":"OmniAD: Data-driven Omni-directional Aerodynamics","type":"publication"},{"authors":["Weiwei Xu","Nobuyuki Umetani","Qianwen Chao","Jie Mao","Xiaogang Jin","Xin Tong"],"categories":null,"content":"","date":1404259200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1404259200,"objectID":"a5d4fd324d8dc888dda856bc185a549f","permalink":"https://cgenglab.github.io/en/publication/sigg14_rigging/","publishdate":"2014-07-02T00:00:00Z","relpermalink":"/en/publication/sigg14_rigging/","section":"publication","summary":"We present a real-time solution for generating detailed clothing deformations from pre-computed clothing shape examples. Given an input pose, it synthesizes a clothing deformation by blending skinned clothing deformations of nearby examples controlled by the body skeleton. Observing that cloth deformation can be well modeled with sensitivity analysis driven by the underlying skeleton, we introduce a sensitivity based method to construct a pose-dependent rigging solution from sparse examples. We also develop a sensitivity based blending scheme to find nearby examples for the input pose and evaluate their contributions to the result. Finally, we propose a stochastic optimization based greedy scheme for sampling the pose space and generating example clothing shapes. Our solution is fast, compact and can generate realistic clothing animation results for various kinds of clothes in real time.","tags":["Machine Learning","Physics Simulation","Cloth Modeling"],"title":"Sensitivity-optimized Rigging for Example-based Real-time Clothing Synthesis","type":"publication"},{"authors":["Nobuyuki Umetani","Yuki Koyama","Ryan Schmidt","Takeo Igarashi"],"categories":null,"content":"","date":1404172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1404172800,"objectID":"51b54652572c4241b83213c7796a06f4","permalink":"https://cgenglab.github.io/en/publication/sigg14_pteromys/","publishdate":"2014-07-01T00:00:00Z","relpermalink":"/en/publication/sigg14_pteromys/","section":"publication","summary":"This paper introduces novel interactive techniques for designing original hand-launched free-flight glider airplanes which can actually fly. The aerodynamic properties of a glider aircraft depend on their shape, imposing significant design constraints. We present a compact and efficient representation of glider aerodynamics that can be fit to real-world conditions using a data-driven method. To do so, we acquire a sample set of glider flight trajectories using a video camera and the system learns a nonlinear relationship between forces on the wing and wing shape. Our acquisition system is much simpler to construct than a wind tunnel, but using it we can efficiently discover a wing model for simple gliding aircraft. Our resulting model can handle general free-form wing shapes and yet agrees sufficiently well with the acquired airplane flight trajectories. Based on this compact aerodynamics model, we present a design tool in which the wing configuration created by a user is interactively optimized to maximize flight-ability. To demonstrate the effectiveness of our tool for glider design by novice users, we compare it with a traditional design workflow.","tags":["Machine Learning","Physics Simulation","Computational Fabrication","Fluid Dynamics","Interactive Modeling","Data-driven Animation"],"title":"Pteromys: Interactive Design and Optimization of Free-formed Free-flight Model Airplanes","type":"publication"},{"authors":["Nobuyuki Umetani","Ryan Schmidt","Jos  Stam"],"categories":null,"content":"","date":1398902400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1398902400,"objectID":"b184d7679fc18f87016488a7b90eb514","permalink":"https://cgenglab.github.io/en/publication/sca14_pbdrod/","publishdate":"2014-05-01T00:00:00Z","relpermalink":"/en/publication/sca14_pbdrod/","section":"publication","summary":"We present a novel method to simulate complex bending and twisting of elastic rods. Elastic rods are commonly simulated using force based methods, such as the finite element method. These methods are accurate, but do not directly fit into the more efficient position-based dynamics framework, since the definition of material frames are not entirely based on positions. We introduce ghost points, which are additional points defined on edges, to naturally endow continuous material frames on discretized rods. We achieve robustness by a novel discretization of the Cosserat theory. The method supports coupling with a frame, a triangle, and a rigid body at the rod’s end point. Our formulation is highly efficient, capable of simulating hundreds of strands in real-time.","tags":["Physics Simulation"],"title":"Position-based Elastic Rod","type":"publication"},{"authors":["Nobuyuki Umetani","Ryan Schmidt"],"categories":null,"content":"","date":1383264e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1383264e3,"objectID":"961cf41ea277a1e159fe037dc844dde7","permalink":"https://cgenglab.github.io/en/publication/sigga13tb_crossanalysis/","publishdate":"2013-11-01T00:00:00Z","relpermalink":"/en/publication/sigga13tb_crossanalysis/","section":"publication","summary":"We propose a novel cross-sectional structural analysis technique that efficiently detects critical stress inside a 3D object. We slice the object into cross-sections and compute stress based on bending momentum equilibrium. Unlike traditional approaches based on finite element methods, our method doesn’t require a volumetric mesh or solution of linear systems, enabling interactive analysis speed. Based on the stress analysis, the orientation of an object is optimized to increase mechnanical strength when manufactured with 3D printing.","tags":["Geometry Processing","Computational Fabrication","Interactive Modeling"],"title":"Cross-sectional Structural Analysis for 3D Printing Optimization","type":"publication"},{"authors":["Nobuyuki Umetani","Takeo Igarashi","Niloy J. Mitra"],"categories":null,"content":"","date":1341100800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1341100800,"objectID":"1352b8a96e383c79ff4f571f46852964","permalink":"https://cgenglab.github.io/en/publication/sigg12_guidedexp/","publishdate":"2012-07-01T00:00:00Z","relpermalink":"/en/publication/sigg12_guidedexp/","section":"publication","summary":"Geometric modeling and the physical validity of shapes are traditionally considered independently. This makes creating aesthetically pleasing yet physically valid models challenging. We propose an interactive design framework for efficient and intuitive exploration of geometrically and physically valid shapes. During any geometric editing operation, the proposed system continuously visualizes the valid range of the parameter being edited. When one or more constraints are violated after an operation, the system generates multiple suggestions involving both discrete and continuous changes to restore validity. Each suggestion also comes with an editing mode that simultaneously adjusts multiple parameters in a coordinated way to maintain validity. Thus, while the user focuses on the aesthetic aspects of the design, our computational design framework helps to achieve physical realizability by providing active guidance to the user. We demonstrate our framework on plank-based furniture design with nail-joint and frictional constraints. We use our system to design a range of examples, conduct a user study, and also fabricate a physical prototype to test the validity and usefulness of the system.","tags":["Physics Simulation","Computational Fabrication","Interactive Modeling"],"title":"Guided Exploration of Physically Valid Shapes for Furniture Design","type":"publication"},{"authors":["Yuki Koyama","Kenshi Takayama","Nobuyuki Umetani","Takeo Igarashi"],"categories":null,"content":"","date":1335830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1335830400,"objectID":"c574272e3f4ca69fe562c7c8d00ecf2c","permalink":"https://cgenglab.github.io/en/publication/sca12_pbdexample/","publishdate":"2012-05-01T00:00:00Z","relpermalink":"/en/publication/sca12_pbdexample/","section":"publication","summary":"We present an example-based elastic deformation method that runs in real time. Example-based elastic deformation was originally presented by Martin et al. [MTGG11], where an artist can intuitively control elastic material behaviors by simply giving example poses. Their FEM-based approach is, however, computationally expensive requiring nonlinear optimization, which hinders its use in real-time applications such as games. Our contribution is to formulate an analogous concept using the shape matching framework, which is fast, robust, and easy to implement. The key observation is that each overlapping local region's right stretch tensor obtained by polar decomposition is a natural choice for a deformation descriptor. This descriptor allows us to represent the pose space as a linear blending of examples. At each time step, the current deformation descriptor is linearly projected onto the example manifold, and then used to modify the rest shape of each local region when computing goal positions. Our approach is two orders of magnitude faster than Martin et al.'s approach while producing comparable example-based elastic deformations.","tags":["Physics Simulation"],"title":"Real-Time Example-Based Elastic Deformation","type":"publication"},{"authors":["Bo Zhu","Michiaki Iwata","Ryo Haraguchi","Takashi Ashihara","Nobuyuki Umetani","Takeo Igarashi","Kazuo Nakazawa"],"categories":null,"content":"","date":1322697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1322697600,"objectID":"5c577cb108e613b11a92a420eefe4924","permalink":"https://cgenglab.github.io/en/publication/sigga11_sketchfluid/","publishdate":"2011-12-01T00:00:00Z","relpermalink":"/en/publication/sigga11_sketchfluid/","section":"publication","summary":"This paper presents a lightweight sketching system that enables interactive illustration of complex fluid systems. Users can sketch on a 2.5-dimensional (2.5D) canvas to design the shapes and connections of a fluid circuit. These input sketches are automatically analyzed and abstracted into a hydraulic graph, and a new hybrid fluid model is used in the background to enhance the illustrations. The system provides rich simple operations for users to edit the fluid system incrementally, and the new internal flow patterns can be simulated in real time. Our system is used to illustrate various fluid systems in medicine, biology, and engineering. We asked professional medical doctors to try our system and obtained positive feedback from them.","tags":["Physics Simulation","Fluid Dynamics","Interactive Modeling"],"title":"Sketch-based Dynamic Illustration of Fluid Systems","type":"publication"},{"authors":["Nobuyuki Umetani","Kenshi Takayama","Jun  Mitani","Takeo Igarashi"],"categories":null,"content":"","date":1314835200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1314835200,"objectID":"c519162918761926ef8164815554adad","permalink":"https://cgenglab.github.io/en/publication/cga10_responsivefem/","publishdate":"2011-09-01T00:00:00Z","relpermalink":"/en/publication/cga10_responsivefem/","section":"publication","summary":"Current computer-aided engineering systems use numerical-simulation methods mainly as offline verification tools to reject designs that don't satisfy the required constraints, rather than as tools to guide users toward better designs. However, integrating real-time finite element method (FEM) into interactive geometric modeling can provide user guidance. During interactive editing, real-time feedback from numerical simulation guides users toward an improved design without tedious trial-and-error iterations. Careful reuse of previous computation results, such as meshes and matrices, on the basis of speed and accuracy trade-offs, have helped produce fast FEM analysis during interactive editing. Several 2D example applications and informal user studies show this approach's effectiveness. Such tools could help nonexpert users design objects that satisfy physical constraints and help those users understand the underlying physical properties.","tags":["Physics Simulation"],"title":"A Responsive Finite Element Method to Aid Interactive Geometric Modeling","type":"publication"},{"authors":["Nobuyuki Umetani","Danny Kaufman","Takeo Igarashi","Eitan Grinsupn"],"categories":null,"content":"","date":1309478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1309478400,"objectID":"e1a6f9950e54077a83c8411764308381","permalink":"https://cgenglab.github.io/en/publication/sigg11_sensitivecouture/","publishdate":"2011-07-01T00:00:00Z","relpermalink":"/en/publication/sigg11_sensitivecouture/","section":"publication","summary":"We present a novel interactive tool for garment design that enables, for the first time, interactive bidirectional editing between 2D patterns and 3D high-fidelity simulated draped forms. This provides a continuous, interactive, and natural design modality in which 2D and 3D representations are simultaneously visible and seamlessly maintain correspondence. Artists can now interactively edit 2D pattern designs and immediately obtain stable accurate feedback online, thus enabling rapid prototyping and an intuitive understanding of complex drape form.","tags":["Physics Simulation","Cloth Modeling","Computational Fabrication","Interactive Modeling"],"title":"Sensitive Couture for Interactive Garment Editing and Modeling","type":"publication"},{"authors":["Nobuyuki Umetani","Jun Mitani","Kenshi Takayama","Takeo Igarashi"],"categories":null,"content":"","date":1277942400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277942400,"objectID":"54b522a05fbc45b6b536bfaeca18372f","permalink":"https://cgenglab.github.io/en/publication/nime10_metallophone/","publishdate":"2010-07-01T00:00:00Z","relpermalink":"/en/publication/nime10_metallophone/","section":"publication","summary":"We introduce an interactive interface for the custom design of metallophones. The shape of each plate must be determined in the design process so that the metallophone will produce the proper tone when struck with a mallet. Unfortunately, the relationship between plate shape and tone is complex, which makes it difficult to design plates with arbitrary shapes. Our system addresses this problem by running a concurrent numerical eigenanalysis during interactive geometry editing. It continuously presents a predicted tone to the user with both visual and audio feedback, thus making it possible to design a plate with any desired shape and tone. We developed this system to demonstrate the effectiveness of integrating real-time finite element method analysis into geometric editing to facilitate the design of custom-made musical instruments. An informal study demonstrated the ability of technically unsophisticated user to apply the system to complex metallophone design.","tags":["Physics Simulation","Computational Fabrication","Sound Simulation"],"title":"Designing Custommade Metallophone with Concurrent Eigenanalysis","type":"publication"},{"authors":["Nobuyuki Umetani","Scott Maclachlan","Kees Oosterlee"],"categories":null,"content":"","date":1257033600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1257033600,"objectID":"dd1ad73ccb9be4972a35eb3cbe6b4999","permalink":"https://cgenglab.github.io/en/publication/nlaa08_multigrid/","publishdate":"2009-11-01T00:00:00Z","relpermalink":"/en/publication/nlaa08_multigrid/","section":"publication","summary":"In this paper, an iterative solution method for a fourth‐order accurate discretization of the Helmholtz equation is presented. The method is a generalization of that presented in (SIAM J. Sci. Comput. 2006; 27:1471–1492), where multigrid was employed as a preconditioner for a Krylov subspace iterative method. The multigrid preconditioner is based on the solution of a second Helmholtz operator with a complex‐valued shift. In particular, we compare preconditioners based on a point‐wise Jacobi smoother with those using an ILU(0) smoother, we compare using the prolongation operator developed by de Zeeuw in (J. Comput. Appl. Math. 1990; 33:1–27) with interpolation operators based on algebraic multigrid principles, and we compare the performance of the Krylov subspace method Bi‐conjugate gradient stabilized with the recently introduced induced dimension reduction method, IDR(s). These three improvements are combined to yield an efficient solver for heterogeneous problems.","tags":["Physics Simulation","Sound Simulation"],"title":"A Multigrid-Based Shifted-Laplacian Preconditioner for a Fourth-Order Helmholtz Discretization","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://cgenglab.github.io/en/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://cgenglab.github.io/en/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]